{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machine in Natural Form"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural form of SVM as an Alternative to the Lagrangian Formulation, and the Need for this Alternative Formulation\n",
    "\n",
    "The original primal problem to solve in SVM is<br>\n",
    "\n",
    "\n",
    "$\\min \\frac{1}{2}{||w||}^{2}$  s.t.   $ 1 -  (y^{i} . ( w^{T}.x^{i} + b ) ) \\leq 0 ,  i = 1, 2, ....., N$ <br>\n",
    "\n",
    "where $w$ are the weights of the classifier, $b$ is the bias term, $i$ refers to each training sample and there are N training samples. <br>\n",
    "\n",
    "The dual form of this primal problem is \n",
    "$\\max \\alpha \\sum_{i=1}^{N} \\alpha_{i} - \\frac{1}{2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\alpha_{i} \\alpha_{j} y^{i}y^{j} x^{i^{T}}x^{j}$  s.t.  $\\alpha_{i}\\geq 0 \\enspace$and$\\enspace\\sum_{i=1}^{N} \\alpha_{i}y^{i} = 0$, $i = 1, 2, ....., N$ <br>\n",
    "\n",
    "However, these primal and dual formulations of SVM assume that the data is (a)linearly-separable and (b)all samples lie on their corresponding sides of the margin (not just the boundary). The constraint of the primal makes sure that for each sample $i$, there is a functional margin of at least 1.\n",
    "\n",
    "\n",
    "However, to handle outliers such that the samples could lie outside their margins (could be on the correct side of the boundary or not), we introduce, for each sample $i$, a variable $\\zeta_{i}$ and allow the functinal margin in the constraint to be less than (even negative sometimes) 1. Note that if this $\\zeta_{i}$ is negative for a sample, it menas that it lies on the wrong side of the boundary since the functional margin is supposed to be at least 1.$ This allows for the violation of the condition (b) mentioned above. Thus, our primal problem becomes<br>\n",
    "\n",
    "$\\min \\frac{1}{2}{||w||}^{2}$  s.t.   $ 1 -  (y^{i} . ( w^{T}.x^{i} + b ) ) \\leq 0 ,  i = 1, 2, ....., N$ <br>\n",
    "or, $\\min \\frac{1}{2}{||w||}^{2}$  s.t.   $ 1 \\leq  (y^{i} . ( w^{T}.x^{i} + b ) ) ,  i = 1, 2, ....., N$ <br>\n",
    "or, $\\min \\frac{1}{2}{||w||}^{2}$  s.t.   $ (y^{i} . ( w^{T}.x^{i} + b ) )  \\geq 1 ,  i = 1, 2, ....., N$ <br>\n",
    "After introducing $\\zeta_{i}$ for each sample $i$\n",
    "or, $\\min \\frac{1}{2}{||w||}^{2}$  s.t.   $ (y^{i} . ( w^{T}.x^{i} + b ) )  \\geq 1 - \\zeta_{i} ,  i = 1, 2, ....., N$, $\\zeta_{i} \\geq 0$ <br>\n",
    "\n",
    "However, condition (a) that the data is linearly-separable still holds. When the data is not linearly separable, (if not applying any trasnformation to the data set to make it lineary-separable in a higher dimension), we can introduce a penalty term in the primal objective such that if a sample is on the wrong side of the boundary defined by the current $w$ and $b$, we can penalize this SVM model. Note that this misclassification happens for a sample $i$ is for this particular sample, $\\zeta_{i}$ is greater than or equal to 1. We can add a penalty of 1 for each misclassification essentially making the new primal objective <br>\n",
    "or, $\\min \\frac{1}{2}{||w||}^{2} + \\sum_{i=1}^{N} I(\\zeta_{i} \\geq 1)$  s.t.   $ (y^{i} . ( w^{T}.x^{i} + b ) )  \\geq 1 - \\zeta_{i} ,  i = 1, 2, ....., N$ , $\\zeta_{i} \\geq 0$<br>\n",
    "\n",
    "However, this added penalty term is not convex and also not all misclassifications are equally wrong since some samples could be just a tiny bit into the wrong side of the boundary in comparison to other misclassified samples. Hence, instead, \n",
    "we replace this misclassification penalty with an approximation using $\\zeta_{i}$ which is essentially the degree in terms of the functional margin by which this particular sample did not make it to the desired side of the margin. Hence, the primal becomes<br>\n",
    "or, $\\min \\frac{1}{2}{||w||}^{2} + \\sum_{i=1}^{N} \\zeta_{i} $  s.t.   $ (y^{i} . ( w^{T}.x^{i} + b ) )  \\geq 1 - \\zeta_{i} ,  i = 1, 2, ....., N$, $\\zeta_{i} \\geq 0$ <br>\n",
    "\n",
    "Notice that the first term in the primal objective tries to maximize the margin since smaller the w norm, larger the margin. The second term, on the other hand, focuses on minimizing the misclassification. Hence, we can introduce a hyperparameter $C$, called as the slack penalty, than can be used as a tradeoff factor between these two objectives of the primal. Hence, the primal objective now becomes<br>\n",
    "or, $\\min \\frac{1}{2}{||w||}^{2} + C\\sum_{i=1}^{N} \\zeta_{i} $  s.t.   $ (y^{i} . ( w^{T}.x^{i} + b ) )  \\geq 1 - \\zeta_{i} ,  i = 1, 2, ....., N$, $\\zeta_{i} \\geq 0$ <br>\n",
    "\n",
    "This problem can be rewritten as<br>\n",
    "or, $\\min \\frac{1}{2}{||w||}^{2} + C\\sum_{i=1}^{N} max (\\,0, 1 -  (y^{i} . ( w^{T}.x^{i} + b ) )\\, ) ,  i = 1, 2, ....., N$ <br>\n",
    "Notice that the $\\zeta_{i} terms disappear in this new form.$ Using max(0,...) ensures that the summation term is either 0 or positive, thus satisfying the constraint $\\zeta_{i} \\geq 0$. Also, $\\sum_{i=1}^{N} max (\\,0, 1 -  (y^{i} . ( w^{T}.x^{i} + b ) )\\, )$ in the objective is the empirical hinge loss. <br>\n",
    "\n",
    "This new objective is a nice convex function which will come handy below.\n",
    "\n",
    "#### Why care about this alternative formulation of SVM when we have Lagrangian formulation that can be solved using a quadratic solver?<br>\n",
    "Given a contraint optimization problem (such as the dual form of our SVM), a solver software finds the optimal parameters of the objective based on the training data samples provided. However, while doing so, if the number of training samples is large, the solver is very inefficient at doing so in terms of speed. Hence, if there were some way we could learn the optimal parameters for our SVM problem at hand (be it the primal or the dual) such that it were not affected in performance by the number of training examples available, it would be great. Turns out, the primal objective that we derived above is a nice convex function. Since it is a convex function, the global optima exists and can be found out using gradient descent (stochastic gradient descent in case the number of training samples is large). Thus, when the number of training samples is high and the solver becomes less efficient, this natual form of the SVM can be used as an alternative. This natural form also allows us for online learning.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "This notebook is insprired from different sources including, but not limited to,\n",
    "Stanford University, Mining of Massive Datasets, SVMs: Soft-Margin SVMs  by Leskovec, Rajaraman, and Ullman\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Species Classification\n",
    "The Iris data set contains sepal and petal lengths and widths for 50 samples each from three different species of Iris flowers. This data set was first presented by  R.A. Fisher in his 1936 paper The Use of Multiple Measurements in Taxonomic Problems. Only the class Iris Setosa is linearly-separable from the other two classes Iris Versicolor and Iris Virginica. For the sake of simplicity, we will merge the other two classes into one. The data set can be found [here](https://www.kaggle.com/uciml/iris). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import sys\n",
    "import copy\n",
    "import pandas as pd\n",
    "import random\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import sklearn\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.20.3.\n"
     ]
    }
   ],
   "source": [
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "    def __init__(self):\n",
    "        self.numerical_features_name_list_including_labels = None\n",
    "        self.categorical_features_namelist = None\n",
    "        #self.scaler_used_for_features = scaler_used_for_features\n",
    "        self.labels = None\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #Custom train_test_split indices generator\n",
    "    def train_test_split_indices(self, len_data, test_split_size):\n",
    "        \n",
    "        #Note that if a sample is to be dropped because of too many missing features, it should be done before this step.\n",
    "        np.random.seed(42)\n",
    "        shuffled_data_indices = np.random.permutation(len_data)\n",
    "        total_test_data = int(test_split_size * len_data)\n",
    "        testing_indices = shuffled_data_indices[:total_test_data]\n",
    "        training_indices = shuffled_data_indices[total_test_data:]\n",
    "        return training_indices, testing_indices\n",
    "    \n",
    "    \n",
    "    def set_numerical_and_categorical_feature_names(self, dataframe):\n",
    "        \n",
    "        #get the names of the numeric feature columns only\n",
    "        self.numerical_features_name_list_including_labels = dataframe.select_dtypes(include=np.number).columns.tolist()\n",
    "        #get the names of the categorical feature columns only\n",
    "        list_of_categorical_feature_names = []\n",
    "        for feature in dataframe.columns:\n",
    "            if dataframe.dtypes[feature] == \"object\":\n",
    "                \n",
    "                list_of_categorical_feature_names.append(feature)\n",
    "        self.categorical_features_namelist = list_of_categorical_feature_names\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vanilla SVM Implementation with Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution begins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class VanillaSVM(BaseEstimator, ClassifierMixin):\n",
    "    '''\n",
    "    Implementation of Vanilla Support Vector Machine algorithm in its natural form.\n",
    "    \n",
    "    Parameters\n",
    "    -------------\n",
    "    c : float, optional, default 1.0\n",
    "        The slack penalty, a tradeoff between maximizing the margin and minimizing the classification errors.\n",
    "    learning_rate : float, optional, default 0.001\n",
    "                    The step size to update the parameters of the model with at each update.\n",
    "    kernel : kernel object, optional, default None\n",
    "             The type of kernel object used by this SVM        \n",
    "    max_epochs : int, optional, default 100\n",
    "                 The number of training iterations to perform by the SVM object.\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, learning_rate = 0.001, c = 1.0, kernel = None, max_epochs = 10):\n",
    "        self.c = c\n",
    "        self.learning_rate = learning_rate\n",
    "        self.kernel = kernel\n",
    "        self.max_epochs = max_epochs\n",
    "        \n",
    "        self.bias_ = 0\n",
    "        \n",
    "        #maintain a dictionary to store the weights computed at the end of each epoch of training\n",
    "        self.weights_dict = {}\n",
    "        self.bias_dict = {}\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def fit(self, X, y = None):\n",
    "\n",
    "        '''\n",
    "        Trains SVM in its natural form.\n",
    "        \n",
    "        Parameters\n",
    "        ----------------\n",
    "        X : arraylike\n",
    "            The training samples in 2D format, corresponding to input features of each sample\n",
    "            to train the vanilla SVM model in its natural form.\n",
    "        y : arraylike, optional, default None\n",
    "            The labels for each sample in X. Some algorithms do not require the label y while some (like SVM) do.\n",
    "            Hence, keep y as optional.\n",
    "        \n",
    "        Returns\n",
    "        ----------------\n",
    "        self : Trained VanillaSVM object\n",
    "               This method returns self for compatibility reasons with sklearn's other interfaces/ functionalities.\n",
    "         \n",
    "        '''\n",
    "        # 1.check that the estimator's hyperparameters are set correctly.\n",
    "        assert type(self.c) == float or type(self.c) == int, \"Data type of parameter c is invalid.\"\n",
    "        assert self.c >= 0 and self.c <= sys.maxsize, \"Value of parameter c is out of possible range.\"\n",
    "        assert self.max_epochs > 0 and self.max_epochs <= sys.maxsize, \"Value of max epochs is invalid.\"\n",
    "        \n",
    "        # 2.check the shape of X, it should be a 2D array to be compatible with sklearn methods later\n",
    "        #This is done by default in _validate_data() method of Base Estimator\n",
    "#         X = self._validate_data(X)\n",
    "#         if y is not None:\n",
    "#             y = self._validate_target(y)\n",
    "            \n",
    "        \n",
    "        \n",
    "        # 3.perform the trianing of SVM here. Here, we will use SGD instead of BGD or MBGD.\n",
    "        self.weights_ = np.random.normal(0, 1, X.shape[-1])\n",
    "        \n",
    "        \n",
    "        iters = 0\n",
    "        np.random.seed(42)\n",
    "        for iter in range(0,self.max_epochs):           \n",
    "            \n",
    "            #shuffle the indices for random updates at each epoch during Stochastic Gradient Descent update\n",
    "            random_indices_ = [idx for idx in range(0, X.shape[0])]\n",
    "            random.shuffle(random_indices_)\n",
    "            \n",
    "            for index_ in range(0,len(random_indices_)):\n",
    "                \n",
    "                gradient_w = None\n",
    "                gradient_b = None\n",
    "                #calculate the gradient of the cost wrt to each parameter/ weight and bias\n",
    "                #There are two parts to our gradient.\n",
    "                gradient_w_1 = self.weights_ #first part is wj for each feature j, which when taken all components at once is w itself.\n",
    "                \n",
    "                gradient_w_2 = None\n",
    "                \n",
    "                \n",
    "                \n",
    "                if y.iloc[random_indices_[index_]].values[0] * (np.dot(self.weights_, X.iloc[random_indices_[index_]].values) + self.bias_) >= 1:\n",
    "                    gradient_w_2 = 0\n",
    "                    gradient_b = 0\n",
    "                else:\n",
    "                    \n",
    "                    gradient_w_2 = -1 * ( y.iloc[random_indices_[index_]].values[0] * X.iloc[random_indices_[index_]].values)\n",
    "                    gradient_b = -1 * y.iloc[random_indices_[index_]].values[0]\n",
    "                \n",
    "                \n",
    "                    \n",
    "                                    \n",
    "                \n",
    "                gradient_w = gradient_w_1 + gradient_w_2\n",
    "                  \n",
    "                \n",
    "                #update the parameters/ weights\n",
    "                self.weights_ = self.weights_ - self.learning_rate * (self.weights_ + (self.c * gradient_w))\n",
    "                self.bias_ = self.bias_ - self.learning_rate * (self.c * (gradient_b))\n",
    "                \n",
    "                \n",
    "                \n",
    "                                                                    \n",
    "   \n",
    "            #update the iteration count\n",
    "            iters += 1\n",
    "            \n",
    "            #save the weights obtained at the end of the current iteration\n",
    "            \n",
    "            \n",
    "#             copy_of_weights = copy.deepcopy(self.weights_)\n",
    "#             copy_of_bias = copy.deepcopy(self.bias_)\n",
    "            self.weights_dict[iter] = self.weights_\n",
    "            self.bias_dict[iter] = self.bias_\n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "        #return self for compatibility reasons with sklearn's other interfaces.\n",
    "        return self\n",
    "       \n",
    "        \n",
    "    def predict_a_sample(self, X):\n",
    "        #SVM classifies using the sign of (WX + b)\n",
    "        prediction_val = np.dot(X, self.weights_dict[self.max_epochs-1]) + self.bias_dict[self.max_epochs-1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        if prediction_val >= 0:\n",
    "            return 1\n",
    "        else:\n",
    "            return -1\n",
    "        \n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4   5            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"C:\\Users\\Being_Aerys\\PycharmProjects\\Machine_Learning_Algorithms_Collection\\Supervised_Methods\\Support_Vector_Machines\\data\\Iris.csv\"\n",
    "raw_data = pd.read_csv(path, sep = \",\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#lets see what unique classes are present.\n",
    "raw_data[\"Species\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0            5.1           3.5            1.4           0.2        1\n",
       "1            4.9           3.0            1.4           0.2        1\n",
       "2            4.7           3.2            1.3           0.2        1\n",
       "3            4.6           3.1            1.5           0.2        1\n",
       "4            5.0           3.6            1.4           0.2        1"
      ]
     },
     "execution_count": 386,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Convert the class labels into +1 and -1 as required by the SVM for mathematical ease\n",
    "\n",
    "raw_data = raw_data.replace([\"Iris-setosa\"],1)\n",
    "raw_data = raw_data.replace([\"Iris-versicolor\", \"Iris-virginica\"],-1)\n",
    "raw_data = raw_data.drop(\"Id\", 1)\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#maintain a fresh copy of the data set for future use\n",
    "copy_of_raw_data = copy.deepcopy(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "22            4.6           3.6            1.0           0.2        1\n",
       "15            5.7           4.4            1.5           0.4        1\n",
       "65            6.7           3.1            4.4           1.4       -1\n",
       "11            4.8           3.4            1.6           0.2        1\n",
       "42            4.4           3.2            1.3           0.2        1"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing = Preprocessing()\n",
    "\n",
    "training_indices, testing_indices = preprocessing.train_test_split_indices(len(raw_data), 0.2)\n",
    "train_set, test_set = raw_data.iloc[training_indices], raw_data.iloc[testing_indices]\n",
    "preprocessing.set_numerical_and_categorical_feature_names(train_set)\n",
    "\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.7</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.1</td>\n",
       "      <td>4.4</td>\n",
       "      <td>1.4</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.8</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Species\n",
       "0            4.6           3.6            1.0           0.2        1\n",
       "1            5.7           4.4            1.5           0.4        1\n",
       "2            6.7           3.1            4.4           1.4       -1\n",
       "3            4.8           3.4            1.6           0.2        1\n",
       "4            4.4           3.2            1.3           0.2        1"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As seen above, the data set indices have changed and we should reset the indices for ease.\n",
    "train_set.reset_index(inplace = True)\n",
    "train_set = train_set.drop(\"index\", 1)\n",
    "train_set.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate training features and labels\n",
    "train_features = train_set[train_set.columns[~train_set.columns.isin([\"Species\"])]]\n",
    "train_labels = pd.DataFrame(train_set[\"Species\"]) #convert to dataframe since a single column becomes a pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 120 entries, 0 to 119\n",
      "Data columns (total 4 columns):\n",
      "SepalLengthCm    120 non-null float64\n",
      "SepalWidthCm     120 non-null float64\n",
      "PetalLengthCm    120 non-null float64\n",
      "PetalWidthCm     120 non-null float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 3.8 KB\n"
     ]
    }
   ],
   "source": [
    "#Summarize the information of the training set\n",
    "train_features.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets instantiate the SVM estimator that we defined and train the model using the training set.\n",
    "svm = VanillaSVM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VanillaSVM(c=1.0, kernel=None, learning_rate=0.001, max_epochs=10)"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fit SVM using the training set\n",
    "svm.fit(X = train_features, y = train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate training features and labels\n",
    "test_features = test_set[test_set.columns[~test_set.columns.isin([\"Species\"])]]\n",
    "test_labels = pd.DataFrame(test_set[\"Species\"]) #convert to dataframe since a single column becomes a pandas Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = []\n",
    "for idx in range(0, len(test_features)):\n",
    "    \n",
    "    test_preds.append(svm.predict_a_sample(X =test_features.iloc[idx] ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
